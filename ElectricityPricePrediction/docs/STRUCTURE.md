# Project Structure & Workflow (Updated)

## ğŸ“ New Organized Directory Structure

```
ElectricityPricePrediction/
â”‚
â”œâ”€â”€ ğŸ“Š data/                          # Raw data files (unchanged)
â”‚   â”œâ”€â”€ GUI_ENERGY_PRICES_2024.csv   # Main price data (Sequence 1)
â”‚   â”œâ”€â”€ CoalPrices.csv               # Monthly coal prices
â”‚   â”œâ”€â”€ MonthlyGasPrice.csv          # Monthly gas prices
â”‚   â”œâ”€â”€ LOAD_DAYAHEAD_FullYear_Data.csv  # Weekly load forecasts
â”‚   â””â”€â”€ [historical data files...]   # 2013-2019 data, other fuels
â”‚
â”œâ”€â”€ ğŸ”§ utils/                         # Data processing utilities
â”‚   â”œâ”€â”€ data_loader_2024.py          # Enhanced data loader (28 features!)
â”‚   â”œâ”€â”€ training_logger.py           # NEW: Training statistics logger
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ ğŸ¤– models/                        # NEW: All models grouped together
â”‚   â”œâ”€â”€ Naive/                       # Baseline models
â”‚   â”‚   â”œâ”€â”€ naive_baseline.py        # Persistence & seasonal baselines
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ XGBoost/                     # Gradient boosting model
â”‚   â”‚   â”œâ”€â”€ xgboost_model.py         # Model implementation
â”‚   â”‚   â”œâ”€â”€ optuna_trial_history.json  # ğŸ”‘ Hyperparameter tuning results
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â””â”€â”€ LSTM/                        # Deep learning model (3-layer!)
â”‚       â”œâ”€â”€ lstm_model.py            # Improved LSTM architecture
â”‚       â”œâ”€â”€ lstm_optuna.py           # Hyperparameter optimization
â”‚       â”œâ”€â”€ best_lstm_params.json    # ğŸ”‘ Best parameters found
â”‚       â”œâ”€â”€ optuna_trial_history.json  # ğŸ”‘ All trial results
â”‚       â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ ğŸ“Š results/                      # NEW: All outputs organized
â”‚   â”œâ”€â”€ plots/                       # All generated visualizations
â”‚   â”‚   â”œâ”€â”€ forecast_last14days.png
â”‚   â”‚   â”œâ”€â”€ metrics_rmse_mae.png
â”‚   â”‚   â”œâ”€â”€ feature_importance.png
â”‚   â”‚   â””â”€â”€ error_distribution.png
â”‚   â”‚
â”‚   â”œâ”€â”€ csv/                         # All CSV results
â”‚   â”‚   â”œâ”€â”€ results_metrics.csv
â”‚   â”‚   â””â”€â”€ ablation_results.csv
â”‚   â”‚
â”‚   â”œâ”€â”€ forecast_values_2024.csv     # Detailed hour-by-hour predictions
â”‚   â””â”€â”€ analysis_results_final.txt   # Summary report
â”‚
â”œâ”€â”€ ğŸ“ training_logs/                # NEW: Training history JSONs
â”‚   â”œâ”€â”€ lstm_training_YYYYMMDD_HHMMSS.json
â”‚   â”œâ”€â”€ xgboost_training_YYYYMMDD_HHMMSS.json
â”‚   â”œâ”€â”€ lstm_latest.json
â”‚   â””â”€â”€ xgboost_latest.json
â”‚
â”œâ”€â”€ ğŸ“ legacy/                       # Old/reference code (preserved)
â”‚   â”œâ”€â”€ forecast_next_day.py
â”‚   â”œâ”€â”€ impact_analysis.py
â”‚   â””â”€â”€ run_2024_analysis.py
â”‚
â”œâ”€â”€ ğŸ“š docs/                         # NEW: Documentation
â”‚   â”œâ”€â”€ STRUCTURE.md                 # This file
â”‚   â””â”€â”€ README.md                    # Project overview
â”‚
â”œâ”€â”€ ğŸš€ run_forecast.py               # MAIN PIPELINE SCRIPT
â”œâ”€â”€ ğŸ“„ LOAD_DAYAHEAD_FullYear_Data.csv  # Weekly load data
â”œâ”€â”€ ğŸ“„ requirements.txt              # Python dependencies
â””â”€â”€ ğŸ“„ .gitignore                    # Git ignore rules
```

## ğŸ”„ Workflow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    1. DATA LOADING                          â”‚
â”‚  utils/data_loader_2024.py (ENHANCED!)                      â”‚
â”‚  â€¢ Load GUI_ENERGY_PRICES_2024.csv (Sequence 1)            â”‚
â”‚  â€¢ Merge fuel prices (Coal, Gas)                           â”‚
â”‚  â€¢ Add cyclical features (hour_sin/cos, day, month)        â”‚
â”‚  â€¢ NEW: Add lag features (1h, 24h, 48h, 168h)             â”‚
â”‚  â€¢ NEW: Add momentum indicators (volatility, changes)      â”‚
â”‚  â€¢ NEW: Add time indicators (weekend, peak hours)          â”‚
â”‚  â€¢ Result: 28 features (was 12)                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                2. TRAIN/TEST SPLIT                          â”‚
â”‚  â€¢ Training: Jan - Oct 19, 2024 (80%)                      â”‚
â”‚  â€¢ Testing:  Oct 19 - Dec 31, 2024 (20%)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                3. MODEL TRAINING                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ Naive Models â”‚  â”‚   XGBoost    â”‚  â”‚ LSTM (NEW!)  â”‚     â”‚
â”‚  â”‚ â€¢ Lag 24h    â”‚  â”‚ â€¢ Optuna     â”‚  â”‚ â€¢ 3 layers   â”‚     â”‚
â”‚  â”‚ â€¢ Lag 168h   â”‚  â”‚   tuning     â”‚  â”‚ â€¢ 128â†’64â†’32  â”‚     â”‚
â”‚  â”‚              â”‚  â”‚ â€¢ Enhanced   â”‚  â”‚ â€¢ Optuna     â”‚     â”‚
â”‚  â”‚              â”‚  â”‚   features   â”‚  â”‚   tuning     â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                             â”‚
â”‚  Training stats saved to training_logs/ as JSON            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                4. PREDICTION                                â”‚
â”‚  All models predict on same test set (Oct-Dec 2024)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                5. EVALUATION & LOGGING                      â”‚
â”‚  â€¢ Calculate RMSE, MAE for each model                      â”‚
â”‚  â€¢ Generate comparison plots                               â”‚
â”‚  â€¢ Save results to results/csv/                            â”‚
â”‚  â€¢ Save training logs to training_logs/                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                6. OUTPUT FILES                              â”‚
â”‚  â€¢ results/csv/results_metrics.csv                         â”‚
â”‚  â€¢ results/forecast_values_2024.csv                        â”‚
â”‚  â€¢ results/plots/*.png (4 plots)                           â”‚
â”‚  â€¢ training_logs/lstm_latest.json                          â”‚
â”‚  â€¢ training_logs/xgboost_latest.json                       â”‚
â”‚  â€¢ models/LSTM/optuna_trial_history.json                   â”‚
â”‚  â€¢ models/XGBoost/optuna_trial_history.json                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ How to Run

### Complete Pipeline
```bash
python run_forecast.py
```

### With Optuna Tuning (LSTM)
```bash
# Run LSTM optimization (20 trials)
python -m models.LSTM.lstm_optuna

# Then run full pipeline
python run_forecast.py
```

### Ablation Study
```bash
python run_forecast.py --ablation
```

## ğŸ“Š Key Improvements

### Enhanced Features (16 new!)
- **Lag Features**: price_lag_1, price_lag_24, price_lag_48, price_lag_168
- **Rolling Stats**: rolling_mean_24, rolling_std_24, rolling_min/max_24
- **Momentum**: price_diff_24, price_change_pct, volatility_24h/168h
- **Time Indicators**: is_weekend, is_peak_hour, is_business_hours

### Improved LSTM Architecture
- **Before**: 2 layers (64â†’32 units)
- **After**: 3 layers (128â†’64â†’32 units)
- Deeper dense layers (128â†’64)
- Better gradient clipping

### Training Transparency
- All training runs logged to `training_logs/`
- JSON files include:
  - Training history (loss curves, epochs)
  - Model configuration (all hyperparameters)
  - Performance metrics (RMSE, MAE, improvement %)
  - Timestamps

## ğŸ“ Important Files

### ğŸ”‘ JSON Result Files (DO NOT DELETE)
- `models/LSTM/best_lstm_params.json` - Best LSTM hyperparameters
- `models/LSTM/optuna_trial_history.json` - All 20 Optuna trials
- `models/XGBoost/optuna_trial_history.json` - XGBoost trials
- `training_logs/*.json` - Training history for each run

### ğŸ“Š CSV Result Files
- `results/csv/results_metrics.csv` - Final RMSE/MAE for all models
- `results/csv/ablation_results.csv` - Feature importance study
- `results/forecast_values_2024.csv` - Hour-by-hour predictions

### ğŸ“ˆ Visualization Files
- `results/plots/forecast_last14days.png` - Time series comparison
- `results/plots/metrics_rmse_mae.png` - Model performance bars
- `results/plots/feature_importance.png` - XGBoost feature ranking
- `results/plots/error_distribution.png` - Residual analysis

## ğŸ¯ Expected Performance

After improvements, target performance hierarchy:
```
Naive Baseline (24h):  ~90 RMSE  (baseline)
XGBoost:              ~60-65 RMSE  (30-35% better)
LSTM (3-layer):       ~50-55 RMSE  (40-45% better)
```

## ğŸ“ Notes

- All JSON files contain timestamps for tracking experiments
- Legacy code preserved in `legacy/` for reference
- All plots regenerated on each run for consistency
- Training logs accumulate over time for improvement tracking
- Enhanced features should significantly improve model performance
